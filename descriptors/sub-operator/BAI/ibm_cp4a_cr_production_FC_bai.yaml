###############################################################################
##
##Licensed Materials - Property of IBM
##
##(C) Copyright IBM Corp. 2021, 2023. All Rights Reserved.
##
##US Government Users Restricted Rights - Use, duplication or
##disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
##
###############################################################################
apiVersion: icp4a.ibm.com/v1
kind: ICP4ACluster
metadata:
  name: icp4adeploy
  labels:
    app.kubernetes.io/instance: ibm-dba
    app.kubernetes.io/managed-by: ibm-dba
    app.kubernetes.io/name: ibm-dba
    release: 23.0.2
spec:

  ## You must read the license agreement: https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-PSZC-SHQFWS and accept the ibm license.
  ## The only valid value is "accept"

  ibm_license: ""

  appVersion: 23.0.2
  ##########################################################################
  ## This section contains the shared configuration for all CP4A components #
  ##########################################################################
  shared_configuration:  
    ## Use this parameter to specify the license for the CP4A deployment and
    ## the possible values are: non-production and production and if not set, the license will
    ## be defaulted to production.  This value could be different from the other licenses in the CR.
    sc_deployment_license: "<Required>"

    ## All CP4A components must use/share the image_pull_secrets to pull images
    image_pull_secrets:
    - ibm-entitlement-key

    ## All CP4A components must use/share the same docker image repository.  For example, if IBM Entitled Registry is used, then
    ## it should be "cp.icr.io".  Otherwise, it will be a local docker registry.
    sc_image_repository: cp.icr.io

    ## Specify the RunAsUser for the security context of the pod.  This is usually a numeric value that corresponds to a user ID.
    ## For non-OCP (e.g., CNCF platforms such as AWS, GKE, etc), this parameter is optional. It is not supported on OCP and ROKS.
    sc_run_as_user:

    ## Optional setting for secure computing mode (seccomp) profile for CP4A containers.  The default seccomp profile is RuntimeDefault on OCP 4.11 (k8s v1.24) or higher. seccomp profile won't be created on OCP 4.10 (k8s v1.23) or lower. 
    ## For more information on seccomp please refer to https://kubernetes.io/docs/tutorials/security/seccomp/ and https://docs.openshift.com/container-platform/4.12/security/seccomp-profiles.html
    ## NOTE: Defining a custom, localhost seccomp profile that is stricter than the default RuntimeDefault profile may cause our pods fail to start.  This custom profile should be created at the worker nodes.
    sc_seccomp_profile:
    #  type: # RuntimeDefault, Localhost, Unconfined
    #  localhost_profile: # Local path of custom seccomp profile when type `Localhost` is used. The custom profile must be accessible by the pod and must exist locally on all worker nodes.  For example: `/profiles/fine-grained.json`.

    images:
      keytool_init_container:
        repository: cp.icr.io/cp/cp4a/bai/dba-keytool-initcontainer
        tag: "23.0.2-IF004"

      ## All CP4A components should use this pull_policy as the default, but it can override by each component
      pull_policy: IfNotPresent

    ## Used to sign all CP4A internal certificates for internal services communications. In most cases, this value should not be changed.
    ## All CP4A components must use/share the root_ca_secret in order for integration
    root_ca_secret: icp4a-root-ca

    ## Shared secret containing a wildcard certificate (and concatenated signers) to be used by all routes, unless overwritten for a specific component route.
    ## If this is not defined, all external routes will be signed with root_ca_secret.
    ## Starting with CP4BA 21.0.3 release, this parameter only applies to non-OCP deployments. For OCP, all external traffic is routed via a 
    ## common front door in Platform UI so custom TLS certificates must be configured in AutomationUIConfig. Please refer 
    ## to https://www.ibm.com/docs/en/cloud-paks/1.0?topic=foundation-custom-resources#automationuiconfig for more information.
    external_tls_certificate_secret:

    ## The optional components to be installed if listed here.  This is normally populated by the User script based on input from the user.  User can
    ## also manually specify the optional components to be deployed here.  For this foundation CR, the optional components are: ums, bas and bai
    sc_optional_components: bai

    ## The deployment type as selected by the user.  Possible values are: Starter and Production.
    sc_deployment_type: Production

    sc_egress_configuration:
      ## Required. Enable or disable egress access to external systems.
      ## If "sc_restricted_internet_access" is defined and has no value set, then default will be "true". 
      ## If "sc_restricted_internet_access" is not defined (e.g., in the case of upgrade, the existing CR will not have sc_restricted_internet_access), then "sc_restricted_internet_access" will be "false"
      sc_restricted_internet_access: true
      ## Optional.  Kubernetes API server namespace(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`.
      ## "{}" can also be used as a value.  It is equivalent to all namespaces (eg: namespaceSelector:{})
      ## Default are "openshift-kube-apiserver", "openshift-apiserver" for OCP and ROKS.
      sc_api_namespace:
      ## Optional.  Kubernetes API server port(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`. 
      ## Default are 443,6443 for OCP and ROKS
      sc_api_port:
      ## Optional.  Kubernetes DNS service namespace(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`.
      ## "{}" can also be used as a value.  It is equivalent to all namespaces (eg: namespaceSelector:{})
      ## Default is "openshift-dns" for OCP and ROKS
      sc_dns_namespace:
      ## Optional.  Kubernetes DNS service port(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`. 
      ## Default are 53,5353 for OCP and ROKS
      sc_dns_port:

    ## The deployment context, which has a default value of "CP4A".  Unless you are instructed to change this value or
    ## know the reason to change this value, please leave the default value.
    sc_deployment_context: "CP4A"

    ## The platform to be deployed specified by the user.  Possible values are: OCP and other.  This is normally populated by the User script
    ## based on input from the user.
    sc_deployment_platform: OCP

    ## This is the deployment hostname suffix, this is optional and the default hostname suffix will be used as {meta.namespace}.router-canonicalhostname
    # sc_deployment_hostname_suffix: "{{ meta.namespace }}"

    ## For ROKS, this is used to enable the creation of ingresses. The default value is "false", which routes will be created.
    sc_ingress_enable: false

    ## For ROKS Ingress, provide TLS secret name for Ingress controller. If you are not using ROKS, comment out this line.
    sc_ingress_tls_secret_name: <Required>

    ## If the root certificate authority (CA) key of the external service is not signed by the operator root CA key, provide the TLS certificate of
    ## the external service to the component's truststore.
    trusted_certificate_list: []

    ## sc_medium_file_storage_classname for BAI 
    ## sc_fast_file_storage_classname for kafka/ES/CS 
    ## sc_block_storage_classname is for Zen
    storage_configuration:
      sc_medium_file_storage_classname: "<Required>"
      sc_fast_file_storage_classname: "<Required>"
      sc_block_storage_classname: "<Required>"

    ## IAM Settings
    sc_iam:
      ## Provide non default admin user for IAM in case you do not want to use cpadmin
      default_admin_username: ""

  ## The beginning section of LDAP configuration for CP4A
  ldap_configuration:
    ## The possible values are: "IBM Security Directory Server" or "Microsoft Active Directory" or "Custom"
    lc_selected_ldap_type: "<Required>"

    ## The name of the LDAP server to connect
    lc_ldap_server: "<Required>"

    ## The port of the LDAP server to connect.  Some possible values are: 389, 636, etc.
    lc_ldap_port: "<Required>"

    ## The LDAP bind secret for LDAP authentication.  The secret is expected to have ldapUsername and ldapPassword keys.  Refer to Knowledge Center for more info.
    lc_bind_secret: ldap-bind-secret

    ## The LDAP base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_base_dn: "<Required>"

    ## Enable SSL/TLS for LDAP communication. Refer to Knowledge Center for more info.
    lc_ldap_ssl_enabled: true

    ## The name of the secret that contains the LDAP SSL/TLS certificate.
    lc_ldap_ssl_secret_name: "<Required>"

    ## The LDAP user name attribute. Semicolon-separated list that must include the first RDN user distinguished names. One possible value is "*:uid" for TDS and "user:sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_name_attribute: "<Required>"

    ## The LDAP user display name attribute. One possible value is "cn" for TDS and "sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_display_name_attr: "<Required>"

    ## The LDAP group base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_group_base_dn: "<Required>"

    ## The LDAP group name attribute.  One possible value is "*:cn" for TDS and "*:cn" for AD. Refer to Knowledge Center for more info.
    lc_ldap_group_name_attribute: "*:cn"

    ## The LDAP group display name attribute.  One possible value for both TDS and AD is "cn". Refer to Knowledge Center for more info.
    lc_ldap_group_display_name_attr: "cn"

    ## The LDAP group membership search filter string.  One possible value is "(|(&(objectclass=groupofnames)(member={0}))(&(objectclass=groupofuniquenames)(uniquemember={0})))" for TDS
    ## and "(&(cn=%v)(objectcategory=group))" for AD.
    lc_ldap_group_membership_search_filter: "<Required>"

    ## The LDAP group membership ID map.  One possible value is "groupofnames:member" for TDS and "memberOf:member" for AD.
    lc_ldap_group_member_id_map: "<Required>"

    ## Set to true if you want to enable LDAP nested search in IAM, by default it is false
    lc_ldap_recursive_search: false

    ## Set to true if you want to enable LDAP pagination in IAM, by default it is false
    lc_enable_pagination: false

    ## If lc_enable_pagination is set to true, then specify the pagination size.  If not specified, the following default values will be used:
    ##  IBM Tivoli Directory Server: 20000; Microsoft Active Directory:1000, and Custom: 4500
    lc_pagination_size: 1000 

    ## add custom group search bases to IAM
    lc_group_searchbase_list: []

    ## add custom user search bases to IAM
    lc_user_searchbase_list: []
    
    ## The lc_ldap_precheck parameter is used to enable or disable LDAP connection check.
    ## If set to "true", then LDAP connection check will be enabled.
    ## if set to "false", then LDAP connection check will not be enabled.
    # lc_ldap_precheck: true

    ## The User script will uncomment the section needed based on user's input from User script.  If you are deploying without the User script,
    ## uncomment the necessary section (depending if you are using Active Directory (ad) or Tivoli Directory Service (tds)) accordingly.
    ad:
      lc_ad_gc_host: "<Required>"
      lc_ad_gc_port: "<Required>"
      lc_user_filter: "(&(sAMAccountName=%v)(objectcategory=user))"
      lc_group_filter: "(&(cn=%v)(objectcategory=group))"
    tds:
      lc_user_filter: "(&(cn=%v)(objectclass=person))"
      lc_group_filter: "(&(cn=%v)(|(objectclass=groupofnames)(objectclass=groupofuniquenames)(objectclass=groupofurls)))"
    custom:
      lc_user_filter: "(&(objectClass=person)(cn=%v))"
      lc_group_filter:  "(&(objectClass=group)(cn=%v))"

  ##############################################################################
  ########      IBM Business Automation Insights (BAI) configuration    ########
  ##############################################################################
  bai_configuration:
    persistence:
      # Set this parameter to false to disable dynamic provisioning as the persistence mode for BAI components.
      useDynamicProvisioning: true
    ## For BAI Standalone, if you have ldap_configuration, then provide ldap user here to import to ZEN
    admin_user: 
    # Name of a secret that is already deployed and contains custom values for configuration parameters.
    # Default value: none.
    bai_secret: ""
    image_credentials:
      # Specific docker registry for the BAI images.
      # If not set, shared_configuration.sc_image_repository is used.
      registry: cp.icr.io/cp/cp4a
    # Image pull policy for BAI images.
    # If not set, shared_configuration.images.pull_policy is used.
    image_pull_policy: "IfNotPresent"

    ## Optional setting for secure computing mode (seccomp) profile for CP4A containers.  The default seccomp profile is RuntimeDefault on OCP 4.11 (k8s v1.24) or higher. seccomp profile won't be created on OCP 4.10 (k8s v1.23) or lower.
    ## For more information on seccomp please refer to https://kubernetes.io/docs/tutorials/security/seccomp/ and https://docs.openshift.com/container-platform/4.12/security/seccomp-profiles.html
    ## NOTE: Defining a custom, localhost seccomp profile that is stricter than the default RuntimeDefault profile may cause our pods fail to start.  This custom profile should be created at the worker nodes.
    ## If it is not set, it will fall back to shared_configuration.sc_seccomp_profile
    seccomp_profile:
    #  type: # RuntimeDefault, Localhost, Unconfined
    #  localhost_profile: # Local path of custom seccomp profile when type `Localhost` is used. The custom profile must be accessible by the pod and must exist locally on all worker nodes.  For example: `/profiles/fine-grained.json`
    
    ## # Disable FIPS for the component (default value is "false"), change it to "true" if you enable FIPS mode for the deployment with shared_configuration.enable_fips = true, but want to disable FIPS mode for the component. 
    # disable_fips: false 
    # This section allow to enhance the configuration of Kafka clients.
    # Those parameters are not mandatory.
    kafka:
      # Indicates whether event consumption starts at the "earliest" offset or at the "latest" offset.
      # Setting it to "latest" means that events sent before BAI is running are not processed.
      # If you want to process events sent before BAI is running set this parameter to "earliest".
      auto_offset_reset: latest
      # You can provide the name of a ConfigMap that is already deployed to Kubernetes
      # and contains Kafka Consumer and producer properties. Default: none.
      properties_config_map: ""
      # The number of seconds before the socket communication with the Kafka server times out. Default: 10000
      socket_timeout_ms: 10000

    settings:
      # Set it to true to enable Apache Kafka data egress. Default: false.
      egress: true
      # URL of an external Kibana OSS. Default: none.
      external_kibana_url:
      # Provide configuration of Apache Kafka topics.
      # All topics must be prefixed with icp4ba-bai
      # If not set, topics with default names as below are created.
      ingress_topic: "icp4ba-bai-ingress"
      egress_topic: "icp4ba-bai-egress"
      service_topic: "icp4ba-bai-service"

    # Setup of BAI Application.
    application_setup:
      image:
        repository: cp.icr.io/cp/cp4a/bai/insights-engine-application-setup
        tag: "23.0.2-IF004"
      # The back-off limit property specifies the number of retries before the setup job is considered failed. Default: 6.
      backoff_limit: 7
      resources:
        requests:
          ## TODO: validate values or remove
          # The minimum memory required, including JVM heap and file system cache, to start the application setup pod.
          memory: "50Mi"
          # The minimum amount of CPU required to start the application setup pod.
          cpu: "200m"
        limits:
          # The maximum memory, including JVM heap and file system cache, to allocate to the application setup pod.
          memory: "120Mi"

    # Setup of Elasticsearch for BAI.
    setup:
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-setup
        tag: "23.0.2-IF004"
      # The back-off limit property specifies the number of retries before the setup job is considered failed. Default: 6.
      backoff_limit: 7
      resources:
        requests:
          # The minimum memory required, including JVM heap and file system cache, to start the setup pod.
          memory: "50Mi"
          # The minimum amount of CPU required to start the setup pod.
          cpu: "200m"
        limits:
          # The maximum memory, including JVM heap and file system cache, to allocate to the setup pod.
          memory: "120Mi"

    # The BAI Management service. Provides public and internal REST endpoints to manage BAI event processing.
    management:
      image:
        repository: cp.icr.io/cp/cp4a/bai/insights-engine-management
        tag: "23.0.2-IF004"
      backend:
        image:
          repository: cp.icr.io/cp/cp4a/bai/insights-engine-management-backend
          tag: "23.0.2-IF004"
      # You can use this parameter to customize the hostname of the management service route.
      # If not set, the value of shared_configuration.sc_deployment_hostname_suffix is used.
      # hostname: "management.bai.{{ shared_configuration.sc_deployment_hostname_suffix }}"
      # The number of Management service replicas. For High Availability,
      # use at least 2 replicas.
      replicas: 2
      # Optional: Enables SSL with an existing certificate for the automatic creation of the OpenShift route
      # for the Management service.
      # If not specified, the value of shared_configuration.external_tls_certificate_secret parameter is used.
      # If this later parameter is not present, the operator generates a self-signed certificate.
      external_tls_secret_name: "{{ meta.name }}-bai-management-external-tls-secret"
      # Optional. The Certificate Authority (CA) used to sign the external TLS secret for the automatic creation
      # of the OpenShift route for the Management service.
      # If you do not want to provide a CA to sign the external TLS certificate, leave this parameter empty.
      external_tls_ca_secret_name:

    flink_pv:
      # The capacity of the persistent volume. Default: "20Gi"
      capacity: "20Gi"
      # If not set, shared_configuration.sc_dynamic_storage_classname is used as a default value.
      storage_class_name: "{{ shared_configuration.storage_configuration.sc_medium_file_storage_classname }}"
      # Provide the name of an existing claim if one is available. By default, a new persistent volume claim is created.
      existing_claim_name: ""

    flink:
      # Use this parameter to increase log verbosity when Flink jobs process events from custom sources through the event forwarder.
      # Valid values: info and trace. Default: info
      log_level: trace
      # Set this parameter to true to increase log verbosity when Flink jobs process fixed-format events.
      # Valid values: true and false. Default: false
      verbose_logs: true

      # The total size of the Flink task manager process.
      # Corresponding Flink parameter: taskmanager.memory.process.size
      # Valid units: https://ci.apache.org/projects/flink/flink-docs-release-1.11/api/java/org/apache/flink/configuration/MemorySize.MemoryUnit.html
      # Default: 1728mb
      task_manager_memory: '1728mb'
      # The total size of the Apache Flink job manager process.
      # Corresponding Flink parameter: jobmanager.memory.process.size
      # Valid units: https://ci.apache.org/projects/flink/flink-docs-release-1.11/api/java/org/apache/flink/configuration/MemorySize.MemoryUnit.html
      # Default: 1728mb
      job_manager_memory: '1728mb'
      # The number of CPUs that are used by Flink task managers (in CPU units).
      # Corresponding Flink parameter: kubernetes.taskmanager.cpu
      # Default: 1
      task_manager_cpu: 1

      # The number of create, delete and update actions to be performed on document indexes in a single request.
      # Default: 1
      elasticsearch_max_actions: 1
      # The time interval at which to flush the buffered actions, regardless of the number or size of buffered actions.
      # If set to -1, a flush internal of 2000 ms is applied when elasticsearch_max_actions is larger than 1, and
      # the buffer is flushed immediately when elasticsearch_max_actions is 1.
      # Otherwise, the specified interval is used.
      # Default: -1
      elasticsearch_flush_interval_ms: -1

      # The interval between checkpoints of an Apache Flink jobs (in milliseconds). Default: 5000
      job_checkpointing_interval: 5000
      # The name of a ConfigMap object that is already deployed to Kubernetes and contains RocksDB properties for Flink.
      # Optional. Default: none.
      rocks_db_properties_config_map: ""

      # Allows to enable the automatic deployment of an OpenShift route to the Flink web interface.
      # On ROKS, if you set the sc_ingress_enable parameter to true, an Ingress is deployed for the Flink web user interface.
      # Default: false
      create_route: true
      # Optional: Enables SSL with an existing certificate for the automatic creation of the OpenShift route
      # for the Flink UI.
      # If not specified, the value of shared_configuration.external_tls_certificate_secret parameter is used.
      # If this later parameter is not present, the operator generates a self-signed certificate.
      external_tls_secret_name: "{{ meta.name }}-bai-flink-ui-external-tls-secret"
      # Optional. The Certificate Authority (CA) used to sign the external TLS secret for the automatic creation
      # of the OpenShift route for the Flink UI.
      # If you do not want to provide a CA to sign the external TLS certificate, leave this parameter empty.
      external_tls_ca_secret_name:

      # The parameters below configure the memory and CPU requests and limits at Kubernetes level.
      # For the valid units of memory requests and limits,
      # see https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#meaning-of-memory.
      # For the valid units of CPU requests and limits,
      # see https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#meaning-of-cpu.
      # The default values are those included below.
      #
      # The memory request for pods of Apache Flink task managers.
      task_manager_memory_request: '1728Mi'
      # The memory limit for pods of Flink task managers.
      task_manager_memory_limit: '1728Mi'
      # The CPU request for pods of Apache Flink task managers.
      task_manager_cpu_request: 1
      # The CPU limit for pods of Apache Flink task managers.
      task_manager_cpu_limit: 1
      # The memory request for pods of Apache Flink job managers.
      job_manager_memory_request: '1728Mi'
      # The memory limit for pods of Apache Flink job managers.
      job_manager_memory_limit: '1728Mi'
      # The CPU request for pods of Apache Flink job managers.
      job_manager_cpu_request: 1
      # The CPU limit for pods of Apache Flink job managers.
      job_manager_cpu_limit: 1
      # The number of additional Flink task managers that must be created to host custom Processing Applications.
      # Required only if using custom Processing Applications.
      # Default: 0
      additional_task_managers: 0

    # The Flink job for processing BPMN events.
    # Enabled automatically if BAI is selected as an optional component of
    # workflow or workflow-workstreams patterns.
    bpmn:
      # Set to true to enable the Flink job for BAW.
      install: false
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-bpmn
        tag: "23.0.2-IF004"
      # The path to the savepoint or checkpoint from which a job will recover.
      # You can use this path to restart the job from a previous state in case of failure.
      # To use the default workflow of the job, leave this option empty.
      recovery_path: ""
      # The number of parallel instances (task slots) to use for running the processing job.
      # For High Availability, use at least 2 parallel instances.
      parallelism: 2
      # The delay in milliseconds before clearing the Flink states used for summary transformation.
      # This value cannot be set to 0 nor be greater than 30 minutes.
      # Otherwise, the default value applies instead.
      end_aggregation_delay: 10000
      # Set this parameter to true if you want time series
      # to be written to Elasticsearch indexes.
      force_elasticsearch_timeseries: false

    # The Flink job for processing BAW Advanced events.
    # Disabled by default. Can be enabled by setting bawadv.install to true.
    bawadv:
      # Set to true to enable the Flink job for BAWAdv.
      install: false
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-bawadv
        tag: "23.0.2-IF004"
      # The path to the savepoint or checkpoint from which a job will recover.
      # You can use this path to restart the job from a previous state in case of failure.
      # To use the default workflow of the job, leave this option empty.
      recovery_path: ""
      # The number of parallel instances (task slots) to use for running the processing job.
      # For High Availability, use at least 2 parallel instances.
      parallelism: 2

    # The Flink job for processing ICM events.
    # Enabled automatically if BAI is selected as an optional component of
    # workflow or workflow-workstreams patterns.
    icm:
      # Set to true to enable the Flink job for ICM.
      install: false
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-icm
        tag: "23.0.2-IF004"
      # The path to the savepoint or checkpoint from which a job will recover.
      # You can use this path to restart the job from a previous state in case of failure.
      # To use the default workflow of the job, leave this option empty.
      recovery_path: ""
      # The number of parallel instances (task slots) to use for running the processing job.
      # For High Availability, use at least 2 parallel instances.
      parallelism: 2
      # Whether the Flink job for ICM events processes events after completion. Default: false
      process_events_after_completion: false
      # Set this parameter to true if you want time series
      # to be written to Elasticsearch indexes.
      force_elasticsearch_timeseries: false

    # The Flink job for processing ODM events.
    # Enabled automatically if BAI is selected as an optional component of
    # decisions pattern.
    odm:
      # Set to true to enable the Flink job for ODM.
      # For ODM, the bai-flink image is used.
      install: false
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-flink
        tag: "23.0.2-IF004"
      # The path to the savepoint or checkpoint from which a job will recover.
      # You can use this path to restart the job from a previous state in case of failure.
      # To use the default workflow of the job, leave this option empty.
      recovery_path: ""
      # The number of parallel instances (task slots) to use for running the processing job.
      # For High Availability, use at least 2 parallel instances.
      parallelism: 2

    # The Flink job for processing Content events.
    # Enabled automatically if BAI is selected as an optional component of
    # content pattern.
    content:
      # Set to true to enable the Flink job for Content.
      install: false
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-content
        tag: "23.0.2-IF004"
      # The path to the savepoint or checkpoint from which a job will recover.
      # You can use this path to restart the job from a previous state in case of failure.
      # To use the default workflow of the job, leave this option empty.
      recovery_path: ""
      # The number of parallel instances (task slots) to use for running the processing job.
      # For High Availability, use at least 2 parallel instances.
      parallelism: 2

    # Configuration of initialization containers.
    init_image:
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-init
        tag: "23.0.2-IF004"

    # Business data dashboarding.
    business_performance_center:
      image:
        repository: cp.icr.io/cp/cp4a/bai/insights-engine-cockpit
        tag: "23.0.2-IF004"
      # Set to false to disable Business Performance Center. Default: true.
      install: true

      ## For SaaS
      # The name of a secret that is already deployed to Kubernetes,
      # which contains configuration information for the Business Performance Center.
      # If you leave this field empty and an UMS instance is installed by the Cloud Pak,
      # the configuration information is automatically generated and stored in a default secret.
      # config_secret_name: ""
      # The port to which the Business Performance Center service API is exposed.
      external_port: 9443
      # The number of Business Performance Center replicas. For High Availability,
      # use at least 2 replicas.
      replicas: 2
      ## For SaaS
      # init_ums:
      #   image:
      #     repository: cp.icr.io/cp/cp4a/aae/dba-umsregistration-initjob
      #     tag: "23.0.2-IF004"
      ## For SaaS
      # oidc:
      #   # The internal communication with single-sign-on (SSO) service.
      #   # If UMS installation can be reach internally, set this parameter to the UMS SSO service name
      #   # Otherwise, set it to the SSO external route hostname.
      #   # If you leave this field empty it will use the default value of the UMS instance installed by the Cloud Pak.
      #   host: ""
      #   # The external communication with the UMS single-sign-on (SSO) service.
      #   # Set this parameter to the SSO external route hostname.
      #   # If you leave this field empty it will use the default value of the UMS instance installed by the Cloud Pak.
      #   external_host: ""
      #   # The host used to retrieve the UMS issuer. Set this parameter to the UMS default route.
      #   # If you leave this field empty it will use the default value of the UMS instance installed by the Cloud Pak.
      #   issuer_host: ""
      #   port: 443
      ## For SaaS
      # Represents the external communication to the UMS team server service. Set this parameter to the team server external route hostname.
      # If you leave this field empty it will use the default value of the UMS instance installed by the Cloud Pak.
      # teamserver_host: ""
      ## For SaaS
      # The external communication to the UMS SCIM service. Set this parameter to the SCIM external route hostname.
      # If you leave this field empty it will use the default value of the UMS instance installed by the Cloud Pak.
      # scim_host: ""
      ## For SaaS
      # The UUID identifier, which is taken from UMS, of the team that you nominate to be the administration team
      # for Business Performance Center.
      # If no admin_team has been specified, a team named bpc_admins will be created automatically and used by BPC.
      # Default: None
      # admin_team: ""
      ## For SaaS
      # The name of a LDAP group to be used by the BPC admin team. The group should be created beforehand. Default: None
      # admin_group: ""
      ## For SaaS
      # Enable automatic creation of the bpc_admins team in UMS if no UUID has been provided under admin_team parameter. Default: true
      # register_admin_team: true
      # Set to true if you want to grant all users access to all data.
      all_users_access: false
      # You can use the redirectURIs parameter to specify the route to access Business Performance Center.
      # The URL must end with a forward slash (/).
      # It is not necessary to specify this parameter when relying on the route created by default.
      redirect_uris: ""
      # The URL to which users are redirected when they log out of Business Performance Center.
      # This URL can be the same as the redirectURIs URL.
      # In this case, users still see the same Business Performance Center window but needs to log in
      # again before they can resume working with Business Performance Center.
      logout_redirect_uris: ""
      # You can use this parameter to customize the hostname of the Business Performance Center route.
      # If not set, the value of shared_configuration.sc_deployment_hostname_suffix is used.
      # hostname: "business-performance-center.bai.{{ shared_configuration.sc_deployment_hostname_suffix }}"
      resources:
        limits:
          # The maximum memory, including JVM heap size and file system cache, to allocate to the Business Performance Center pod.
          # Adjust this parameter value for better resource allocation and better performance.
          memory: "2Gi"
          # The maximum amount of CPU to allocate to the Business Performance Center pod.
          # Adjust this parameter value for better resource allocation and better performance.
          cpu: "2000m"
      # Set this parameter to false if you do not want
      # the Business Performance Center plug-in to be automatically installed into Navigator.
      auto_plugin: true
      # Optional: Enables SSL with an existing certificate for the automatic creation of the OpenShift route
      # for the Business Performance Center.
      # If not specified, the value of shared_configuration.external_tls_certificate_secret parameter is used.
      # If this later parameter is not present, the operator generates a self-signed certificate.
      external_tls_secret_name: "{{ meta.name }}-bai-bperf-external-tls-secret"
      # Optional. The Certificate Authority (CA) used to sign the external TLS secret for the automatic creation
      # of the OpenShift route for the Business Performance Center.
      # If you do not want to provide a CA to sign the external TLS certificate, leave this parameter empty.
      external_tls_ca_secret_name:
      alert:
        # The Kafka alert topic. Default is icp4ba-bai-alerts
        topic: "icp4ba-bai-alerts"
        # The Kafka alert topic replication factor. Default is kafka size
        replication_factor:
        # Enables Kafka alert notifier. Default is true
        enable_notifier: true
        # Set the alert computation polling interval. Default is 5000
        polling_interval: "5000"
